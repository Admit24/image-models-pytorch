
#### 1. 基础配置

##### (1) check pytorch version

```python
torch.__version__               # PyTorch version
torch.version.cuda              # Corresponding CUDA version
torch.backends.cudnn.version()  # Corresponding cuDNN version
torch.cuda.get_device_name(0)   # GPU type
```

##### (2) update pytorch

```sh
conda update pytorch torchvision -c pytorch
```

##### (3) random seed setting 

```python
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
```

##### (4) 指定程序运行在特定显卡上：

在命令行指定环境变量

```sh
CUDA_VISIBLE_DEVICES=0,1 python train.py
```

在代码中指定

```python
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
```

##### (5) 判断是否有CUDA支持

```
torch.cuda.is_available()
torch.set_default_tensor_type('torch.cuda.FloatTensor')   
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
```

##### (6) 设置为cuDNN benchmark模式

Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。

```python
toch.backends.cudnn.benchmark = True
```

如果想要避免这种结果波动，设置

```python
torch.backends.cudnn.deterministic = True
```

##### (7) 手动清除GPU存储

有时Control-C中止运行后GPU存储没有及时释放，需要手动清空。在PyTorch内部可以

```python
torch.cuda.empty_cache() 
```

或在命令行可以先使用ps找到程序的PID，再使用kill结束该进程

```sh
 ps aux | grep python    kill -9 [pid] 
```

或者直接重置没有被清空的GPU

```sh
nvidia-smi --gpu-reset -i [gpu_id]
```
